{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbc9cfd1",
   "metadata": {},
   "source": [
    "# Collect Data\n",
    "\n",
    "In this notebook, we collect data of the [12 candidates of the French presidential campaign](https://fr.wikipedia.org/wiki/Candidats_%C3%A0_l%27%C3%A9lection_pr%C3%A9sidentielle_fran%C3%A7aise_de_2022):\n",
    "- Nathalie Arthaud  \n",
    "- Nicolas Dupont-Aignan \n",
    "- Anne Hidalgo \n",
    "- Yannick Jadot \n",
    "- Jean Lassalle \n",
    "- Marine Le Pen \n",
    "- Emmanuel Macron \n",
    "- Jean-Luc Mélenchon \n",
    "- Valérie Pécresse \n",
    "- Philippe Poutou \n",
    "- Fabien Roussel \n",
    "- Éric Zemmour \n",
    "\n",
    "We explore the following social networks:\n",
    "> Twitter\n",
    "> Youtube\n",
    "> Instagram\n",
    "\n",
    "We plan to study textual data so we collect tweets, video descriptions on youtube and text posts on Instagram. I give in the following the required criteria such that it respect the [laws](https://www.cnil.fr/fr/communication-politique-quelles-regles-pour-la-collecte-de-donnees-sur-les-reseaux-sociaux):\n",
    "\n",
    "- I, Mathilde Boltenhagen, will collect, use and delete the data;\n",
    "- Raw data will not be shared and deleted before the 30th of April;\n",
    "- The data will be used to extract information, the entire analytic process will be shared in this folder;\n",
    "- Any correction, access, deletion and other actions given by [les droits Informatique et Libertés](https://www.cnil.fr/fr/les-droits-pour-maitriser-vos-donnees-personnelles) will be considered, please contact [Mathilde Boltenhagen](https://www.linkedin.com/in/mathilde-boltenhagen/);\n",
    "- The right to make a complaint to the CNIL;\n",
    "\n",
    "\n",
    "The main question is:\n",
    "*How do the candidates communicate through the social networks?*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd33f15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dateutil import parser\n",
    "import datetime\n",
    "import os\n",
    "import json\n",
    "import tweepy\n",
    "from instagramy import InstagramUser \n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "import pytz\n",
    "from apiclient.discovery import build "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddbdf35",
   "metadata": {},
   "source": [
    "Ids of the different apps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87231bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidatesId = []\n",
    "candidatesId.append({\"name\" : \"Nathalie Arthaud\", \"twitterId\" : \"n_arthaud\", \"youtubeId\" : \"UUZsh-MrJftAOP_-ZgRgLScw\", \"instagramId\" : \"nathalie_arthaud_lo\"})\n",
    "candidatesId.append({\"name\" : \"Nicolas Dupont-Aignan\", \"twitterId\" : \"dupontaignan\", \"youtubeId\" : \"UUfA5DnCDX3Ixy5QOAMGtBlA\", \"instagramId\" : \"dupontaignan\"})\n",
    "candidatesId.append({\"name\" : \"Anne Hidalgo\", \"twitterId\" : \"Anne_Hidalgo\", \"youtubeId\" : \"UUcvK-yrz2_dSJUSNDJfq7JA\", \"instagramId\" : \"annehidalgo\"})\n",
    "candidatesId.append({\"name\" : \"Yannick Jadot\", \"twitterId\" : \"yjadot\", \"youtubeId\" : \"UUw7v4zI01GNLUO6jYgIHx0w\", \"instagramId\" : \"yannickjadot\"})\n",
    "candidatesId.append({\"name\" : \"Jean Lassalle\", \"twitterId\" : \"jeanlassalle\", \"youtubeId\" : \"UUdUat4f2yol7iMpCYoFUmNg\", \"instagramId\" : \"jeanlassalleoff\"})\n",
    "candidatesId.append({\"name\" : \"Marine Le Pen\", \"twitterId\" : \"MLP_officiel\", \"youtubeId\" : \"UUU3z3px1_RCqYBwrs8LJVWg\", \"instagramId\" : \"marine_lepen\"})\n",
    "candidatesId.append({\"name\" : \"Emmanuel Macron\", \"twitterId\" : \"EmmanuelMacron\", \"youtubeId\" : \"UUFqGa9uitcB-fWyNZK2xImw\", \"instagramId\" : \"emmanuelmacron\"})\n",
    "candidatesId.append({\"name\" : \"Jean-Luc Mélenchon\", \"twitterId\" : \"JLMelenchon\", \"youtubeId\" : \"UUk-_PEY3iC6DIGJKuoEe9bw\", \"instagramId\" : \"jlmelenchon\"})\n",
    "candidatesId.append({\"name\" : \"Valérie Pécresse\", \"twitterId\" : \"vpecresse\", \"youtubeId\" : \"UUXAKlEXGwoavQuOMaNBeaXw\", \"instagramId\" : \"vpecresse\"})\n",
    "candidatesId.append({\"name\" : \"Philippe Poutou\", \"twitterId\" : \"PhilippePoutou\", \"youtubeId\" : None, \"instagramId\" : \"philippepoutou_officiel\"})\n",
    "candidatesId.append({\"name\" : \"Fabien Roussel\", \"twitterId\" : \"Fabien_Roussel\", \"youtubeId\" : None, \"instagramId\" : \"fabien_roussel\"})\n",
    "candidatesId.append({\"name\" : \"Éric Zemmour\", \"twitterId\" : \"ZemmourEric\", \"youtubeId\" : \"UUjTbZBXEw-gplUAnMXLYHpg\", \"instagramId\" : \"ericzemmour_\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f76a5a0",
   "metadata": {},
   "source": [
    "## TWITTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ff6777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get last date of the previous collect\n",
    "def getLastDate(file_name, column_name = \"created_at\"):\n",
    "    # if the file exists, get maximal date, otherwise, get new year date\n",
    "    try :\n",
    "        df = pd.read_csv(file_name, sep=\";\")\n",
    "        try :\n",
    "            return parser.parse(df[column_name].max())\n",
    "        except TypeError:\n",
    "            return parser.parse(\"2022-01-01 00:01:01+00:00\")\n",
    "    except FileNotFoundError:\n",
    "        return parser.parse(\"2022-01-01 00:01:01+00:00\")\n",
    "\n",
    "lastupdate = getLastDate(\"twitter.csv\")\n",
    "lastupdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b5973b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read keys \n",
    "with open('twitter.json', 'r') as f:\n",
    "    twitter_info = json.load(f)\n",
    "\n",
    "consumer_key = twitter_info['consumer_key'] \n",
    "consumer_secret = twitter_info['consumer_secret']\n",
    "access_token = twitter_info['access_token'] \n",
    "access_token_secret = twitter_info['access_token_secret'] \n",
    "\n",
    "# set auth\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed89240a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the output, format is ['id', 'text', 'retweet_count','favorite_count', 'created_at']\n",
    "collectedTwitterData = []\n",
    "\n",
    "# for all candidates, get new tweets\n",
    "for candidate_id in candidatesId:\n",
    "    print(candidate_id[\"name\"])\n",
    "    # for each page of tweets\n",
    "    cursor = tweepy.Cursor(api.user_timeline, id = candidate_id[\"twitterId\"]).items(200)\n",
    "    for tweet in cursor:\n",
    "        # not a RT or a reply and after 2022 01 01\n",
    "        if tweet.created_at >= lastupdate and(list(tweet.text)[:2] != ['R', 'T']) & (list(tweet.text)[0]!='@') :\n",
    "            collectedTwitterData.append([candidate_id[\"name\"], tweet.text, tweet.retweet_count , tweet.favorite_count, tweet.created_at])\n",
    "        # we got all the tweets\n",
    "        elif tweet.created_at < lastupdate: \n",
    "            print(tweet.created_at)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4374239b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check last before saving, note that you should not \n",
    "collectedTwitterData[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f96b9b",
   "metadata": {},
   "source": [
    "Please, ensure to have to rights to save the data: [Developer Agreement and Policy](https://developer.twitter.com/en/developer-terms/agreement-and-policy), [More about restricted uses of the Twitter APIs](https://developer.twitter.com/en/developer-terms/more-on-restricted-use-cases). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d58b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put into a df and save\n",
    "df = pd.DataFrame(collectedTwitterData, columns = ['id', 'text', 'retweet_count','favorite_count', 'created_at'])\n",
    "\n",
    "# Exporting the DataFrame as csv\n",
    "df.to_csv('twitter.csv', index=False, sep=\";\", mode='a', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de60b2fe",
   "metadata": {},
   "source": [
    "## YOUTUBE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8e6c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('twitter.json', 'r') as f:\n",
    "    youtube_key = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b501b4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# launches requests per channel and per videos to get stats\n",
    "def getAllDescriptionsOfAnAccount(accountId, name, output):\n",
    "    nextPageToken = None\n",
    "    dateOfPost = None\n",
    "    # while we have new videos to explore for accountId \n",
    "    while  dateOfPost is None or dateOfPost <= lastupdate :\n",
    "        # get api\n",
    "        youtube = build('youtube', 'v3',developerKey = youtube_key[\"apikey\"])\n",
    "        # request 50 videos of channel accountId\n",
    "        request = youtube.playlistItems().list(part = \"snippet\", playlistId = accountId, maxResults = 50,\n",
    "                                               pageToken = nextPageToken)\n",
    "        response = request.execute()\n",
    "        for item in response[\"items\"]:\n",
    "            dateOfPost = parser.parse(item[\"snippet\"][\"publishedAt\"])\n",
    "            if dateOfPost < lastupdate:\n",
    "                break\n",
    "            else:\n",
    "                # get stats\n",
    "                request = youtube.videos().list( part = \"statistics\", id = item[\"snippet\"][\"resourceId\"][\"videoId\"])\n",
    "                rating = request.execute()\n",
    "                # append to list of outputs\n",
    "                if 'commentCount' not in rating[\"items\"][0][\"statistics\"]:\n",
    "                    rating[\"items\"][0][\"statistics\"]['commentCount'] = 0\n",
    "                output.append([name,item[\"snippet\"][\"publishedAt\"],\n",
    "                             item[\"snippet\"][\"description\"],\n",
    "                             rating[\"items\"][0][\"statistics\"][\"likeCount\"],\n",
    "                             rating[\"items\"][0][\"statistics\"][\"commentCount\"]])\n",
    "        if 'nextPageToken' not in response:\n",
    "            break\n",
    "        else:\n",
    "            nextPageToken = response['nextPageToken']\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3b18d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get description of all candidates\n",
    "lastupdate = getLastDate(\"youtube.csv\")\n",
    "\n",
    "output = [] \n",
    "for c in candidatesId:\n",
    "    if c[\"youtubeId\"]:\n",
    "        output = getAllDescriptionsOfAnAccount(c[\"youtubeId\"],c[\"name\"],output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a978591e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22055f2",
   "metadata": {},
   "source": [
    "Please, ensure to have to rights to save the data: [Policies](https://developers.google.com/youtube/terms/developer-policies). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d14dc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put into a df and save\n",
    "df = pd.DataFrame(output, columns = ['id', 'created_at', 'description','like_count', 'comment_count'])\n",
    "\n",
    "# Exporting the DataFrame as csv\n",
    "df.to_csv('youtube.csv',  index=False, sep=\";\", mode='a', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176e69b9",
   "metadata": {},
   "source": [
    "## Instagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18833582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read keys \n",
    "with open('instagram.json', 'r') as f:\n",
    "    insta_info = json.load(f)\n",
    "    \n",
    "sessionid = insta_info[\"sessionid\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeae8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendNextText(name, dateOfPost, e, output):\n",
    "    # per element, we check if the date is ok and description not null\n",
    "    if dateOfPost is None or dateOfPost >= lastupdate :\n",
    "    if len(e[\"node\"][\"edge_media_to_caption\"][\"edges\"]) != 0 :\n",
    "        text = e[\"node\"][\"edge_media_to_caption\"][\"edges\"][0][\"node\"][\"text\"]\n",
    "    else:\n",
    "        text = \"\"\n",
    "    output.append([name,text, e[\"node\"][\"edge_media_preview_liked_by\"][\"count\"], \n",
    "                   e[\"node\"][\"edge_media_to_comment\"][\"count\"],\n",
    "                   dateOfPost])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e8abcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPhotoDescriptions(name, json, lastupdate, output):\n",
    "    # for all media photo\n",
    "    for e in json['entry_data']['ProfilePage'][0][\"graphql\"][\"user\"][\"edge_owner_to_timeline_media\"][\"edges\"]:\n",
    "        # get date of the post\n",
    "        dateOfPost = datetime.datetime.fromtimestamp(e[\"node\"][\"taken_at_timestamp\"]).replace(tzinfo=pytz.UTC)\n",
    "        # check the date and description and append to output\n",
    "        output = appendNextText(name, dateOfPost, e, output)\n",
    "        \n",
    "    # iterate with TOKEN\n",
    "    nextindex = json['entry_data']['ProfilePage'][0][\"graphql\"][\"user\"][\"edge_owner_to_timeline_media\"]['page_info']['end_cursor']\n",
    "    while dateOfPost is None or dateOfPost >= lastupdate :\n",
    "        idUser = json['entry_data']['ProfilePage'][0][\"graphql\"][\"user\"][\"id\"]\n",
    "        # get next media \n",
    "        rrr= requests.get(\"https://www.instagram.com/graphql/query/?query_id=17888483320059182&id=\"+idUser+\"&first=12&after=\"+nextindex, \n",
    "                   headers= {\"Cookie\":\"sessionid=\" + sessionid})\n",
    "        # same loop as before\n",
    "        for e in rrr.json()[\"data\"][\"user\"][\"edge_owner_to_timeline_media\"][\"edges\"]:\n",
    "            dateOfPost = datetime.datetime.fromtimestamp(e[\"node\"][\"taken_at_timestamp\"]).replace(tzinfo=pytz.UTC)\n",
    "            output = appendNextText(name, dateOfPost, e, output)\n",
    "        nextindex = rrr.json()[\"data\"][\"user\"][\"edge_owner_to_timeline_media\"]['page_info']['end_cursor']   \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afc0de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfDescription = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d95c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting the profile \n",
    "for idC in candidatesId:\n",
    "    print(idC[\"instagramId\"])\n",
    "    user = InstagramUser(idC[\"instagramId\"], sessionid = sessionid) \n",
    "\n",
    "    # return list of dicts \n",
    "    info = user.get_json() \n",
    "    listOfDescription += getPhotoDescriptions(idC[\"name\"],info,lastupdate,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65a9631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that you should not keep instagram data. \n",
    "listOfDescription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72642c50",
   "metadata": {},
   "source": [
    "Please note that you should not use this instagram script: [Policies](https://developers.facebook.com/docs/instagram-api/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
